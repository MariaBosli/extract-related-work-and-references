{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "EaTWaWbzA3ia",
        "outputId": "9d35bc40-a434-45f6-f897-119d89afc1f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#monter le drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install langchain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "-8k7lrWHC-w6",
        "outputId": "2ae84c96-75cd-455e-ec72-45d3b5c3af94"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.2.0-py3-none-any.whl (973 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/973.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.6/973.7 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m972.8/973.7 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m973.7/973.7 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.6-py3-none-any.whl (28 kB)\n",
            "Collecting langchain-core<0.3.0,>=0.2.0 (from langchain)\n",
            "  Downloading langchain_core-0.2.0-py3-none-any.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.9/307.9 kB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.2.0-py3-none-any.whl (23 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.59-py3-none-any.whl (121 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.2/121.2 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.7.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.3.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.21.2-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3.0,>=0.2.0->langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting packaging<24.0,>=23.2 (from langchain-core<0.3.0,>=0.2.0->langchain)\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading orjson-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.18.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.0->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: packaging, orjson, mypy-extensions, jsonpointer, typing-inspect, marshmallow, jsonpatch, langsmith, dataclasses-json, langchain-core, langchain-text-splitters, langchain\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "Successfully installed dataclasses-json-0.6.6 jsonpatch-1.33 jsonpointer-2.4 langchain-0.2.0 langchain-core-0.2.0 langchain-text-splitters-0.2.0 langsmith-0.1.59 marshmallow-3.21.2 mypy-extensions-1.0.0 orjson-3.10.3 packaging-23.2 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_community\n"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srdrWIPggTgc",
        "outputId": "6ed22cd9-2b3f-45f0-c867-4b11d9fcc2fb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.2.0-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.9.5)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.6.6)\n",
            "Requirement already satisfied: langchain<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.2.0)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.2.0)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.1.59)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (1.25.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (8.3.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.21.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.0->langchain_community) (0.2.0)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.0->langchain_community) (2.7.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain_community) (23.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain_community) (3.10.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2024.2.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (4.11.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.0->langchain_community) (2.4)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.0->langchain_community) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.0->langchain_community) (2.18.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
            "Installing collected packages: langchain_community\n",
            "Successfully installed langchain_community-0.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install sentence_transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5p1AK-tHo7l",
        "outputId": "286fa69e-e93b-4b1b-aeac-d7e8a83a9448",
        "collapsed": true
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentence_transformers\n",
            "  Downloading sentence_transformers-2.7.0-py3-none-any.whl (171 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/171.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m153.6/171.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m171.5/171.5 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.40.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.66.4)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.2.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.11.4)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.20.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (3.14.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (4.11.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (23.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (0.4.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, sentence_transformers\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 sentence_transformers-2.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r /content/drive/MyDrive/requirement.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "hPl2e96NClAd",
        "outputId": "3d3723d3-8e01-42ce-e211-75da30da7f51"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-sm@ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl (from -r /content/drive/MyDrive/requirement.txt (line 30))\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py==1.4.0 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/requirement.txt (line 1)) (1.4.0)\n",
            "Collecting accelerate==0.20.3 (from -r /content/drive/MyDrive/requirement.txt (line 2))\n",
            "  Downloading accelerate-0.20.3-py3-none-any.whl (227 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.6/227.6 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp==3.9.5 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/requirement.txt (line 3)) (3.9.5)\n",
            "Requirement already satisfied: aiosignal==1.3.1 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/requirement.txt (line 4)) (1.3.1)\n",
            "Collecting argon2-cffi==21.3.0 (from -r /content/drive/MyDrive/requirement.txt (line 5))\n",
            "  Downloading argon2_cffi-21.3.0-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: argon2-cffi-bindings==21.2.0 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/requirement.txt (line 6)) (21.2.0)\n",
            "Collecting asttokens==2.0.8 (from -r /content/drive/MyDrive/requirement.txt (line 7))\n",
            "  Downloading asttokens-2.0.8-py2.py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/requirement.txt (line 8)) (1.6.3)\n",
            "Requirement already satisfied: async-timeout==4.0.3 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/requirement.txt (line 9)) (4.0.3)\n",
            "Collecting attrs==22.1.0 (from -r /content/drive/MyDrive/requirement.txt (line 10))\n",
            "  Downloading attrs-22.1.0-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: backcall==0.2.0 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/requirement.txt (line 11)) (0.2.0)\n",
            "Collecting beautifulsoup4==4.11.1 (from -r /content/drive/MyDrive/requirement.txt (line 12))\n",
            "  Downloading beautifulsoup4-4.11.1-py3-none-any.whl (128 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bleach==5.0.1 (from -r /content/drive/MyDrive/requirement.txt (line 13))\n",
            "  Downloading bleach-5.0.1-py3-none-any.whl (160 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.9/160.9 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting blis==0.7.9 (from -r /content/drive/MyDrive/requirement.txt (line 14))\n",
            "  Downloading blis-0.7.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cachetools==5.3.1 (from -r /content/drive/MyDrive/requirement.txt (line 15))\n",
            "  Downloading cachetools-5.3.1-py3-none-any.whl (9.3 kB)\n",
            "Collecting catalogue==2.0.8 (from -r /content/drive/MyDrive/requirement.txt (line 16))\n",
            "  Downloading catalogue-2.0.8-py3-none-any.whl (17 kB)\n",
            "Collecting certifi==2023.5.7 (from -r /content/drive/MyDrive/requirement.txt (line 17))\n",
            "  Downloading certifi-2023.5.7-py3-none-any.whl (156 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m157.0/157.0 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cffi==1.15.1 (from -r /content/drive/MyDrive/requirement.txt (line 18))\n",
            "  Downloading cffi-1.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (441 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m441.8/441.8 kB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting charset-normalizer==3.1.0 (from -r /content/drive/MyDrive/requirement.txt (line 19))\n",
            "  Downloading charset_normalizer-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.3/199.3 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting click==8.1.3 (from -r /content/drive/MyDrive/requirement.txt (line 20))\n",
            "  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.6/96.6 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorama==0.4.6 (from -r /content/drive/MyDrive/requirement.txt (line 21))\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting confection==0.0.4 (from -r /content/drive/MyDrive/requirement.txt (line 22))\n",
            "  Downloading confection-0.0.4-py3-none-any.whl (32 kB)\n",
            "Collecting contourpy==1.0.5 (from -r /content/drive/MyDrive/requirement.txt (line 23))\n",
            "  Downloading contourpy-1.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.9/295.9 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cycler==0.11.0 (from -r /content/drive/MyDrive/requirement.txt (line 24))\n",
            "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
            "Collecting cymem==2.0.7 (from -r /content/drive/MyDrive/requirement.txt (line 25))\n",
            "  Downloading cymem-2.0.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34 kB)\n",
            "Requirement already satisfied: dataclasses-json==0.6.6 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/requirement.txt (line 26)) (0.6.6)\n",
            "Collecting debugpy==1.6.3 (from -r /content/drive/MyDrive/requirement.txt (line 27))\n",
            "  Downloading debugpy-1.6.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting decorator==5.1.1 (from -r /content/drive/MyDrive/requirement.txt (line 28))\n",
            "  Downloading decorator-5.1.1-py3-none-any.whl (9.1 kB)\n",
            "Requirement already satisfied: defusedxml==0.7.1 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/requirement.txt (line 29)) (0.7.1)\n",
            "Requirement already satisfied: entrypoints==0.4 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/requirement.txt (line 31)) (0.4)\n",
            "Collecting executing==1.1.1 (from -r /content/drive/MyDrive/requirement.txt (line 32))\n",
            "  Downloading executing-1.1.1-py2.py3-none-any.whl (22 kB)\n",
            "Collecting fastjsonschema==2.16.2 (from -r /content/drive/MyDrive/requirement.txt (line 33))\n",
            "  Downloading fastjsonschema-2.16.2-py3-none-any.whl (22 kB)\n",
            "Collecting filelock==3.12.2 (from -r /content/drive/MyDrive/requirement.txt (line 34))\n",
            "  Downloading filelock-3.12.2-py3-none-any.whl (10 kB)\n",
            "Collecting findspark==2.0.1 (from -r /content/drive/MyDrive/requirement.txt (line 35))\n",
            "  Downloading findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\n",
            "Collecting flatbuffers==23.5.26 (from -r /content/drive/MyDrive/requirement.txt (line 36))\n",
            "  Downloading flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
            "Collecting fonttools==4.37.4 (from -r /content/drive/MyDrive/requirement.txt (line 37))\n",
            "  Downloading fonttools-4.37.4-py3-none-any.whl (960 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m960.8/960.8 kB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: frozenlist==1.4.1 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/requirement.txt (line 38)) (1.4.1)\n",
            "Requirement already satisfied: fsspec==2023.6.0 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/requirement.txt (line 39)) (2023.6.0)\n",
            "Collecting funcy==2.0 (from -r /content/drive/MyDrive/requirement.txt (line 40))\n",
            "  Downloading funcy-2.0-py2.py3-none-any.whl (30 kB)\n",
            "Requirement already satisfied: future==0.18.3 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/requirement.txt (line 41)) (0.18.3)\n",
            "Collecting gast==0.4.0 (from -r /content/drive/MyDrive/requirement.txt (line 42))\n",
            "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Collecting gensim==4.3.1 (from -r /content/drive/MyDrive/requirement.txt (line 43))\n",
            "  Downloading gensim-4.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.4/26.4 MB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting google-auth==2.20.0 (from -r /content/drive/MyDrive/requirement.txt (line 44))\n",
            "  Downloading google_auth-2.20.0-py2.py3-none-any.whl (181 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.5/181.5 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting google-auth-oauthlib==1.0.0 (from -r /content/drive/MyDrive/requirement.txt (line 45))\n",
            "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: google-pasta==0.2.0 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/requirement.txt (line 46)) (0.2.0)\n",
            "Collecting graphviz==0.5.1 (from -r /content/drive/MyDrive/requirement.txt (line 47))\n",
            "  Downloading graphviz-0.5.1-py2.py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: greenlet==3.0.3 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/requirement.txt (line 48)) (3.0.3)\n",
            "Collecting grpcio==1.56.0 (from -r /content/drive/MyDrive/requirement.txt (line 49))\n",
            "  Downloading grpcio-1.56.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m88.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: h5py==3.9.0 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/requirement.txt (line 50)) (3.9.0)\n",
            "Collecting huggingface-hub==0.15.1 (from -r /content/drive/MyDrive/requirement.txt (line 51))\n",
            "  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting idna==3.4 (from -r /content/drive/MyDrive/requirement.txt (line 52))\n",
            "  Downloading idna-3.4-py3-none-any.whl (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.5/61.5 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: imbalanced-learn==0.10.1 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/requirement.txt (line 53)) (0.10.1)\n",
            "Collecting ipykernel==6.16.0 (from -r /content/drive/MyDrive/requirement.txt (line 54))\n",
            "  Downloading ipykernel-6.16.0-py3-none-any.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.4/138.4 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ipython==8.5.0 (from -r /content/drive/MyDrive/requirement.txt (line 55))\n",
            "  Downloading ipython-8.5.0-py3-none-any.whl (752 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m752.0/752.0 kB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: ipython-genutils==0.2.0 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/requirement.txt (line 56)) (0.2.0)\n",
            "Collecting ipywidgets==8.0.2 (from -r /content/drive/MyDrive/requirement.txt (line 57))\n",
            "  Downloading ipywidgets-8.0.2-py3-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.4/134.4 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting iso8601==2.1.0 (from -r /content/drive/MyDrive/requirement.txt (line 58))\n",
            "  Downloading iso8601-2.1.0-py3-none-any.whl (7.5 kB)\n",
            "Collecting jax==0.4.13 (from -r /content/drive/MyDrive/requirement.txt (line 59))\n",
            "  Downloading jax-0.4.13.tar.gz (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m69.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jedi==0.18.1 (from -r /content/drive/MyDrive/requirement.txt (line 60))\n",
            "  Downloading jedi-0.18.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m72.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Jinja2==3.1.2 (from -r /content/drive/MyDrive/requirement.txt (line 61))\n",
            "  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.1/133.1 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting joblib==1.2.0 (from -r /content/drive/MyDrive/requirement.txt (line 62))\n",
            "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jsonpatch==1.33 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/requirement.txt (line 63)) (1.33)\n",
            "Requirement already satisfied: jsonpointer==2.4 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/requirement.txt (line 64)) (2.4)\n",
            "Collecting jsonschema==4.16.0 (from -r /content/drive/MyDrive/requirement.txt (line 65))\n",
            "  Downloading jsonschema-4.16.0-py3-none-any.whl (83 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.1/83.1 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jupyter==1.0.0 (from -r /content/drive/MyDrive/requirement.txt (line 66))\n",
            "  Downloading jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB)\n",
            "Collecting jupyter-console==6.4.4 (from -r /content/drive/MyDrive/requirement.txt (line 67))\n",
            "  Downloading jupyter_console-6.4.4-py3-none-any.whl (22 kB)\n",
            "Collecting jupyter-core==4.11.1 (from -r /content/drive/MyDrive/requirement.txt (line 68))\n",
            "  Downloading jupyter_core-4.11.1-py3-none-any.whl (88 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.4/88.4 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jupyter_client==7.3.5 (from -r /content/drive/MyDrive/requirement.txt (line 69))\n",
            "  Downloading jupyter_client-7.3.5-py3-none-any.whl (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.1/132.1 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jupyterlab-pygments==0.2.2 (from -r /content/drive/MyDrive/requirement.txt (line 70))\n",
            "  Downloading jupyterlab_pygments-0.2.2-py2.py3-none-any.whl (21 kB)\n",
            "Collecting jupyterlab-widgets==3.0.3 (from -r /content/drive/MyDrive/requirement.txt (line 71))\n",
            "  Downloading jupyterlab_widgets-3.0.3-py3-none-any.whl (384 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m384.1/384.1 kB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras==2.12.0 (from -r /content/drive/MyDrive/requirement.txt (line 72))\n",
            "  Downloading keras-2.12.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m80.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keyboard==0.13.5 (from -r /content/drive/MyDrive/requirement.txt (line 73))\n",
            "  Downloading keyboard-0.13.5-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.1/58.1 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting kiwisolver==1.4.4 (from -r /content/drive/MyDrive/requirement.txt (line 74))\n",
            "  Downloading kiwisolver-1.4.4-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m80.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain==0.1.20 (from -r /content/drive/MyDrive/requirement.txt (line 75))\n",
            "  Downloading langchain-0.1.20-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m66.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-community==0.0.38 (from -r /content/drive/MyDrive/requirement.txt (line 76))\n",
            "  Downloading langchain_community-0.0.38-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m86.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core==0.1.52 (from -r /content/drive/MyDrive/requirement.txt (line 77))\n",
            "  Downloading langchain_core-0.1.52-py3-none-any.whl (302 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.9/302.9 kB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-text-splitters==0.0.2 (from -r /content/drive/MyDrive/requirement.txt (line 78))\n",
            "  Downloading langchain_text_splitters-0.0.2-py3-none-any.whl (23 kB)\n",
            "Collecting langcodes==3.3.0 (from -r /content/drive/MyDrive/requirement.txt (line 79))\n",
            "  Downloading langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.6/181.6 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: langsmith==0.1.59 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/requirement.txt (line 80)) (0.1.59)\n",
            "Collecting lda2vec==0.16.10 (from -r /content/drive/MyDrive/requirement.txt (line 81))\n",
            "  Downloading lda2vec-0.16.10.tar.gz (13 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting libclang==16.0.0 (from -r /content/drive/MyDrive/requirement.txt (line 82))\n",
            "  Downloading libclang-16.0.0-py2.py3-none-manylinux2010_x86_64.whl (22.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.9/22.9 MB\u001b[0m \u001b[31m65.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Markdown==3.4.3 (from -r /content/drive/MyDrive/requirement.txt (line 83))\n",
            "  Downloading Markdown-3.4.3-py3-none-any.whl (93 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.9/93.9 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting MarkupSafe==2.1.1 (from -r /content/drive/MyDrive/requirement.txt (line 84))\n",
            "  Downloading MarkupSafe-2.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Requirement already satisfied: marshmallow==3.21.2 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/requirement.txt (line 85)) (3.21.2)\n",
            "Collecting matplotlib==3.6.2 (from -r /content/drive/MyDrive/requirement.txt (line 86))\n",
            "  Downloading matplotlib-3.6.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting matplotlib-inline==0.1.6 (from -r /content/drive/MyDrive/requirement.txt (line 87))\n",
            "  Downloading matplotlib_inline-0.1.6-py3-none-any.whl (9.4 kB)\n",
            "Requirement already satisfied: missingno==0.5.2 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/requirement.txt (line 88)) (0.5.2)\n",
            "Collecting mistune==2.0.4 (from -r /content/drive/MyDrive/requirement.txt (line 89))\n",
            "  Downloading mistune-2.0.4-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: ml-dtypes==0.2.0 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/requirement.txt (line 90)) (0.2.0)\n",
            "Requirement already satisfied: mpmath==1.3.0 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/requirement.txt (line 91)) (1.3.0)\n",
            "Requirement already satisfied: multidict==6.0.5 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/requirement.txt (line 92)) (6.0.5)\n",
            "Collecting murmurhash==1.0.9 (from -r /content/drive/MyDrive/requirement.txt (line 93))\n",
            "  Downloading murmurhash-1.0.9-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21 kB)\n",
            "Requirement already satisfied: mypy-extensions==1.0.0 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/requirement.txt (line 94)) (1.0.0)\n",
            "Collecting nbclient==0.7.0 (from -r /content/drive/MyDrive/requirement.txt (line 95))\n",
            "  Downloading nbclient-0.7.0-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nbconvert==7.2.1 (from -r /content/drive/MyDrive/requirement.txt (line 96))\n",
            "  Downloading nbconvert-7.2.1-py3-none-any.whl (271 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m271.6/271.6 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nbformat==5.7.0 (from -r /content/drive/MyDrive/requirement.txt (line 97))\n",
            "  Downloading nbformat-5.7.0-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nest-asyncio==1.5.6 (from -r /content/drive/MyDrive/requirement.txt (line 98))\n",
            "  Downloading nest_asyncio-1.5.6-py3-none-any.whl (5.2 kB)\n",
            "Collecting networkx==3.1 (from -r /content/drive/MyDrive/requirement.txt (line 99))\n",
            "  Downloading networkx-3.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m85.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting neupy==0.6.5 (from -r /content/drive/MyDrive/requirement.txt (line 100))\n",
            "  Downloading neupy-0.6.5-py2.py3-none-any.whl (197 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m197.2/197.2 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nltk==3.8 (from -r /content/drive/MyDrive/requirement.txt (line 101))\n",
            "  Downloading nltk-3.8-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m76.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting notebook==6.4.12 (from -r /content/drive/MyDrive/requirement.txt (line 102))\n",
            "  Downloading notebook-6.4.12-py3-none-any.whl (9.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m72.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numexpr==2.8.4 (from -r /content/drive/MyDrive/requirement.txt (line 103))\n",
            "  Downloading numexpr-2.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (381 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m381.4/381.4 kB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy==1.23.5 (from -r /content/drive/MyDrive/requirement.txt (line 104))\n",
            "  Downloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m62.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: oauthlib==3.2.2 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/requirement.txt (line 105)) (3.2.2)\n",
            "Collecting opencv-python==4.9.0.80 (from -r /content/drive/MyDrive/requirement.txt (line 106))\n",
            "  Downloading opencv_python-4.9.0.80-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (62.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.2/62.2 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opt-einsum==3.3.0 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/requirement.txt (line 107)) (3.3.0)\n",
            "Requirement already satisfied: orjson==3.10.3 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/requirement.txt (line 108)) (3.10.3)\n",
            "Requirement already satisfied: packaging==23.2 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/requirement.txt (line 109)) (23.2)\n",
            "Collecting pandas==2.0.2 (from -r /content/drive/MyDrive/requirement.txt (line 110))\n",
            "  Downloading pandas-2.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m62.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pandocfilters==1.5.0 (from -r /content/drive/MyDrive/requirement.txt (line 111))\n",
            "  Downloading pandocfilters-1.5.0-py2.py3-none-any.whl (8.7 kB)\n",
            "Collecting parso==0.8.3 (from -r /content/drive/MyDrive/requirement.txt (line 112))\n",
            "  Downloading parso-0.8.3-py2.py3-none-any.whl (100 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.8/100.8 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pathy==0.10.2 (from -r /content/drive/MyDrive/requirement.txt (line 113))\n",
            "  Downloading pathy-0.10.2-py3-none-any.whl (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.9/48.9 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pickleshare==0.7.5 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/requirement.txt (line 114)) (0.7.5)\n",
            "Collecting Pillow==9.2.0 (from -r /content/drive/MyDrive/requirement.txt (line 115))\n",
            "  Downloading Pillow-9.2.0-cp310-cp310-manylinux_2_28_x86_64.whl (3.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m88.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting plotly==5.11.0 (from -r /content/drive/MyDrive/requirement.txt (line 116))\n",
            "  Downloading plotly-5.11.0-py2.py3-none-any.whl (15.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.3/15.3 MB\u001b[0m \u001b[31m75.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting preshed==3.0.8 (from -r /content/drive/MyDrive/requirement.txt (line 117))\n",
            "  Downloading preshed-3.0.8-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.7/124.7 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting progressbar2==3.34.3 (from -r /content/drive/MyDrive/requirement.txt (line 118))\n",
            "  Downloading progressbar2-3.34.3-py2.py3-none-any.whl (25 kB)\n",
            "Collecting prometheus-client==0.14.1 (from -r /content/drive/MyDrive/requirement.txt (line 119))\n",
            "  Downloading prometheus_client-0.14.1-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting prompt-toolkit==3.0.31 (from -r /content/drive/MyDrive/requirement.txt (line 120))\n",
            "  Downloading prompt_toolkit-3.0.31-py3-none-any.whl (382 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m382.3/382.3 kB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting protobuf==4.23.3 (from -r /content/drive/MyDrive/requirement.txt (line 121))\n",
            "  Downloading protobuf-4.23.3-cp37-abi3-manylinux2014_x86_64.whl (304 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m304.5/304.5 kB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting psutil==5.9.2 (from -r /content/drive/MyDrive/requirement.txt (line 122))\n",
            "  Downloading psutil-5.9.2-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (282 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m282.8/282.8 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pure-eval==0.2.2 (from -r /content/drive/MyDrive/requirement.txt (line 123))\n",
            "  Downloading pure_eval-0.2.2-py3-none-any.whl (11 kB)\n",
            "Collecting pyasn1==0.5.0 (from -r /content/drive/MyDrive/requirement.txt (line 124))\n",
            "  Downloading pyasn1-0.5.0-py2.py3-none-any.whl (83 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.9/83.9 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyasn1-modules==0.3.0 (from -r /content/drive/MyDrive/requirement.txt (line 125))\n",
            "  Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.3/181.3 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pycparser==2.21 (from -r /content/drive/MyDrive/requirement.txt (line 126))\n",
            "  Downloading pycparser-2.21-py2.py3-none-any.whl (118 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.7/118.7 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydantic==1.10.9 (from -r /content/drive/MyDrive/requirement.txt (line 127))\n",
            "  Downloading pydantic-1.10.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m93.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Pygments==2.13.0 (from -r /content/drive/MyDrive/requirement.txt (line 128))\n",
            "  Downloading Pygments-2.13.0-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m73.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyLDAvis==3.4.1 (from -r /content/drive/MyDrive/requirement.txt (line 129))\n",
            "  Downloading pyLDAvis-3.4.1-py3-none-any.whl (2.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m67.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyparsing==3.0.9 (from -r /content/drive/MyDrive/requirement.txt (line 130))\n",
            "  Downloading pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.3/98.3 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyrsistent==0.18.1 (from -r /content/drive/MyDrive/requirement.txt (line 131))\n",
            "  Downloading pyrsistent-0.18.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.8/115.8 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyserial==3.5 (from -r /content/drive/MyDrive/requirement.txt (line 132))\n",
            "  Downloading pyserial-3.5-py2.py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.6/90.6 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil==2.8.2 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/requirement.txt (line 133)) (2.8.2)\n",
            "Collecting python-utils==3.8.1 (from -r /content/drive/MyDrive/requirement.txt (line 134))\n",
            "  Downloading python_utils-3.8.1-py2.py3-none-any.whl (27 kB)\n",
            "Collecting pytz==2022.4 (from -r /content/drive/MyDrive/requirement.txt (line 135))\n",
            "  Downloading pytz-2022.4-py2.py3-none-any.whl (500 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m500.8/500.8 kB\u001b[0m \u001b[31m46.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: Could not find a version that satisfies the requirement pywin32==304 (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for pywin32==304\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/drive/MyDrive/llm.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "slI0pbfBA9_Y",
        "outputId": "ec8f124f-1baa-438a-ad03-ebf84a304e79"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain/__init__.py:29: UserWarning: Importing HuggingFaceHub from langchain root module is no longer supported. Please use langchain_community.llms.HuggingFaceHub instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/drive/MyDrive/references.py"
      ],
      "metadata": {
        "id": "779uJZyEsvox"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/drive/MyDrive/exract_related_work.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QAEo4ew9DKpt",
        "outputId": "8b3a7865-6548-43f7-9220-a71c2ea52385",
        "collapsed": true
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain/__init__.py:29: UserWarning: Importing HuggingFaceHub from langchain root module is no longer supported. Please use langchain_community.llms.HuggingFaceHub instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `HuggingFaceHub` was deprecated in LangChain 0.0.21 and will be removed in 0.3.0. Use HuggingFaceEndpoint instead.\n",
            "  warn_deprecated(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 0.3.0. Use invoke instead.\n",
            "  warn_deprecated(\n",
            "* Many studies have been suggested in the literature\n",
            "    handling DL techniques for the purpose of diagnosing and\n",
            "    diagnosing patients with COVID-19 virus.\n",
            "    Soares et al. [6] conducted a study to determine Covid-19\n",
            "    using deep learning methods, xDNN, ResNet, GoogleNet,\n",
            "    VGG16, AlexNet, Decision Tree and AdoBoost. The dataset\n",
            " \n",
            "* In another study, authors used deep learning models to\n",
            "    extract features from chest X-ray images of patients\n",
            "    suffering from COVID-1   used is 80:20 reserved for training and testing. Consequently\n",
            "    of the studies, the xDNN deep learning model reached the\n",
            "    highest accuracy value of 97.38%. Cifci [7] also tried to detect\n",
            "    COVID-19 with AlexNet and Inception-V4 models. It used\n",
            "    4640 (80%) CT images to train the model and 1160 (20%) CT\n",
            "    images to test it. Looking at the experimental results, AlexNet\n",
            "    performed better than Inceptionv4. AlexNet achieved an\n",
            "    accuracy of 94.74%.\n",
            "    Wang et al. [8] experimented on pathogen-infected\n",
            "    lung CT images using the ResNet50 model. They used 618\n",
            "    lung CT images to train the model and 155 lung CT images to\n",
            "    test it. In the experimental results, it was observed that the\n",
            "    ResNet50 model reached an accuracy of 82.9%.\n",
            "    In the study conducted by Barstugan et al. [9], they\n",
            "    experimented on lung CT images usingconfirmed\n",
            "    COVID-19 cases in 1,119 CT scans. Using the Inception\n",
            "    model, they put into practice the transfer learning techniques\n",
            "    of deep learning and achieved 89.5% accuracy. Lawton et al.\n",
            "    [9] evaluated the performance of standard histogram\n",
            "    equalization and contrast limited adaptive histogram\n",
            "    equalization as well as transfer learning models to determine\n",
            "    Covid-19 with deep learning methods. In the Sars Cov 2 CT\n",
            "    Scan dataset, the highest performing model was VGG19 with\n",
            "    95.75% accuracy.\n",
            "    https://arxiv.org/abs/2004.08925\n",
            "    https://www.researchgate.net/publication/342943695_Detection_of_COVID-19_using_Chest_CT_Scans_with_Deep_Learning_Techniques\n",
            "    https://www.researchgate.net/publication/3, which was applied with contrast bound adaptive\n",
            "    histogram equalization.\n",
            "    In the study directed by Rahimzadeh et al. [10] on the\n",
            "    detection of COVID-19 in Iran, a new dataset containing\n",
            "    48260 CT (tomography) scan images was used. Image\n",
            "    classification with ResNet50V2, a 50-layer network trained on\n",
            "    the ImageNet dataset, achieved 98.49% accuracy in CT\n",
            "    scanning. In the study conducted by Pathak et al. [11],\n",
            "    COVID-19 detection was made from computed tomography\n",
            "    images based on deformable convolution networks.\n",
            "    The study conducted by Seyedhosseini et al. [12] used\n",
            "    a dataset of 3228 CT images containing 1248 COVID-19\n",
            "    images. In this study, 4 different networks were used to\n",
            "    classify the images and the best result was obtained from\n",
            "    the DenseNet121 network with 88% accuracy.\n",
            "    In the study conducted byep transfer learning. The developed model\n",
            "    achieved training and testing accuracy of 96.22% and 93.01%,\n",
            "    respectively.\n",
            "    Bansal et al. [12] tried to detect Covid-19 using deep\n",
            "    learning methods ResNet50, VGG16, SVM models. The\n",
            "    dataset used is 80:20 reserved for training and testing. Thus,\n",
            "    496 data were used for the 1985 test for training. During the\n",
            "    training phase, the 5-fold cross-validation method was used.\n",
            "    The model with the highest accuracy was ResNet50 with\n",
            "    95.16%. In the research of Khan et al. [13], the X-ray\n",
            "    dataset was used for the method of deep learning VGG19\n",
            "    architecture. The dataset is divided into 80:20 sets for\n",
            "    training and testing. The model achieves 91.17% accuracy\n",
            "    in the training phase and 92.25% in the testing phase. In the\n",
            "    research of Zhang et al. [14], the V study conducted by Bukharia et al. [13],\n",
            "    COVID-19 detection was made using the ResNet50 technique\n",
            "    from X-Ray images. During the diagnosis process, They\n",
            "    obtained 98.18%, 98.14%, 98.24% and 98.19% accuracy,\n",
            "    precision, recall and F1-Score from the model, respectively.\n",
            "    Jaiswal et al. [14] used DenseNet201, ResNet152V2,\n",
            "    VGG16 and InceptionResNet models from DL methods to\n",
            "    detect Covid-19. As a result of the studies, the test validation\n",
            "    rate for DenseNet201 was 96.25%. Silva et al. [15] used\n",
            "    CNN models to detect Covid-19. The authors have obtained\n",
            "    accuracy, precision, recall and F1-Score values of 85.60%,\n",
            "    86.40%, 83.50% and 84.90%, respectively.\n",
            " [15], unlike\n",
            "    others, performed cross dataset analysis with Sars Cov 2 CT\n",
            "    Scan dataset and CovidCT dataset. EfficientNet, one of the\n",
            "    deep learning models, was used in the study, and the highest\n",
            "    accuracy value was 87.68.\n",
            "* COVID-19 detection methods can be categorized into two\n",
            "    groups: 1) unimodal detection methods, 2) multi-modal\n",
            "    methods. We discuss the symptoms and techniques used within\n",
            "    these categories below.\n",
            "    A. Unimodal Automated Methods for COVID-19 Symptom\n",
            "    Detection\n",
            "    1. X-ray Methods\n",
            "    Chest X-ray imaging is typically used to diagnose\n",
            "    pneumonia, tuberculosis, and other chest infections.\n",
            "    X-ray imaging is fast and easy to use, which makes it\n",
            "    a popular choice for COVID-19 detection. In a study\n",
            "    of 100 patients, Wang et al. [16] found that the\n",
            "    radiographic findings of COVID-    At the early stages of the pandemic, many studies focused on\n",
            "    unimodal automated methods for COVID-19 detection, in\n",
            "    particular on X-ray [14], CT [15], or ultrasound [21] images of\n",
            "    patients’ chests to identify anomalies [25].\n",
            "    Despite the high accuracy of AI enhanced imaging\n",
            "    identification, these diagnosis methods are not portable and must\n",
            "    be performed in hospitals or medical centers where the\n",
            "    equipment is available. Furthermore, specially trained\n",
            "    technicians are needed in o-site, and the patients are exposed\n",
            "    to radiation.\n",
            "    In parallel, there have been several studies on the\n",
            "    automated detection of COVID-19 from cough sounds.\n",
            "    In [27], the authors proposed a deep learning\n",
            "    model based on a CNN and a recurrent neural network\n",
            "    (RNN) to classify cough sounds. They used a dataset of\n",
            "    2244 cough sounds, labeled as healthy, bronchitis,rder to operate these systems, which\n",
            "    further restricts the testing capability for identifying COVID-19\n",
            "    in the field. Therefore, researchers have been investigating the\n",
            "    use of more widely available signals for development of early\n",
            "    detection of COVID symptoms [26]. These include, for\n",
            "    example, vocal signals such as coughing [22], [27]–[29] or\n",
            "    breathing [23], [30], [31].\n",
            "    Coughing is a very common and natural physiological\n",
            "    behavior which is associated with several viral respirator\n",
            "    infections, including influenza and COVID-19 [22], [32], [33].\n",
            "    While there is no single definitive feature of a cough that\n",
            "    can be attributed to COVID-19, it is believed that the sound\n",
            "    of coughs from patients with COVID-19 may have certain\n",
            "    characteristics that can be used to help identify them\n",
            "    [22], [27], [29].\n",
            "    The initialy\n",
            "    infections including COVID-19 [32], [33]. Depending on the\n",
            "    infected and the irritant locations within the respiratory system,\n",
            "    the coughing sound produced by different respiratory infections\n",
            "    have distinct features [34]–[39]. Recent studies have found that\n",
            "    COVID-19 infects the respiratory system in a distinct way [27],\n",
            "    [40]–[42]. By comparing the CT analysis of COVID-19 infected\n",
            "    patients with non-COVID pneumonia, the COVID-19 patients\n",
            "    are more likely to develop a peripheral dorsal distribution of\n",
            "    infiltrates and intra-lobular septal thickening [27]. These distinct\n",
            "    chest CT features of COVID-19 can potentially be used as a\n",
            "    biomarker for COVID-19 diagnosis. In this paper, we propose a\n",
            "    deep learning based system for COVID-19 diagnosis using the\n",
            "    coughing sounds. Specifically, we train a deep learning model to\n",
            "    learn the feature representations ofistribution, groundglass\n",
            "    opacity, vascular thickening, and reverse halo sign [16],\n",
            "    [40].\n",
            "    Based on the difference of changes in the respiratory system,\n",
            "    a COVID-19 patient would likely produce a distinct coughing\n",
            "    sound that can be identified by learning algorithms [16]. For\n",
            "    example, in [28], Convolutional Neural Networks (CNN) were\n",
            "    used to identify people with COVID through forced coughing as\n",
            "    input signals. When processing the raw coughing signal, four\n",
            "    distinct biomarkers i.e., the intensity, spectral centroid,\n",
            "    spectral bandwidth, and spectral rolloff were extracted and\n",
            "    used as features for the CNN. The proposed model was able to\n",
            "    achieve an accuracy of 97.1% in identifying COVID patients.\n",
            "    Similar results were also obtained in [46].\n",
            "    Apart from coughing, the change in lung condition can also be\n",
            "    detected by analyzing the respiratory rate (RR). The RR isncluding muscular degradation, changes in\n",
            "    vocal cords, changes in sentiment/mood, and changes in the\n",
            "    lungs/respiratory tract were utilized as part of the detection\n",
            "    criteria.Another common symptom of COVID-19 infection is\n",
            "    changes in the breathing rhythm or shortness of breath. In [23],\n",
            "    frequency-modulated continuous wave signals were classified\n",
            "    using a XGBoost classifier and a Mel-frequency cepstral\n",
            "    coefficient (MFCC) feature extractor. Five different breathing\n",
            "    patterns were a part of the classification: normal, shallow,\n",
            "    deep, fast, and slow. The accuracy of the model was 91.1%.\n",
            "    The study in [24] used a VGGish feature extractor and an\n",
            "    LSTM classifier to classify cough sounds. The accuracy of\n",
            "    the model was 92.4%. The dataset in this study contained 1374\n",
            "    cough sounds. The study in [25] used analyzed: normal breathing, deep/quick breathing,\n",
            "    deep breathing, quick breathing, and holding the breath.\n",
            "    Despite the fact that fever is the most common symptoms of\n",
            "    COVID-19 [20], a unimodal temperature measurement is not\n",
            "    sufficient to determine whether a person is infected by the virus,\n",
            "    as fever alone is a very common symptom of many illnesses\n",
            "    [43]. Furthermore, fever can be less common in younger age\n",
            "    groups that have been diagnosed with mild or moderate COVID\n",
            "    [44]. As a resut, the temperature measurement is not included in\n",
            "    the list of symptoms.\n",
            "    The study also showed that the most common symptoms of COVID-19\n",
            "    are dry cough and fatigue [20], which also appear to be the most\n",
            "    common symptoms of the common cold or the flu [45]. However,\n",
            "    the study [20] also showed that the probability of having COVID-19\n",
            "    is significantly higher for a person with both dry coughult, temperature can only be utilized in combination\n",
            "    with other modes (symptoms) in multimodal analysis.\n",
            "    B. Multi-modal Automated Methods for COVID-19 Detection\n",
            "    Since COVID-19 patients are usually presented with multiple\n",
            "    symptoms [24], multi-modal deep learning classification can be\n",
            "    used to improve the accuracy of COVID-19 diagnoses [17]. For\n",
            "    example, in [30], a COVID-19 Identification ResNet (CIdeR)\n",
            "    classifier used cough and breathing together to determine the\n",
            "    probability of COVID-19. The model was trained on a dataset\n",
            "    of 1,300 coughs and 1,250 breaths from 1,300 patients. The\n",
            "    model achieved 92.8% accuracy. Other respiratory sounds,\n",
            "    such as sneezing and vocal cord sounds, can also be used in\n",
            "    multi-modal deep learning models. The model in [31] used a\n",
            "    combination of cough COVID-positivity. In [17], more modes were\n",
            "    utilized. Namely, Logistic Regression (LR) and Support Vector\n",
            "    Machines (SVM) were used to classify breathing, coughing, and\n",
            "    speech signals separately and a Decision Tree classifier was used\n",
            "    to classify a group of other symptoms such as fatigue, muscle\n",
            "    pain, and loss of smell. The outputs of each classifier were\n",
            "    prediction scores and were all given equal weights to determine\n",
            "    the overall probability of COVID.\n",
            "    However, when investigatiing the relevance of each mode to\n",
            "    COVID-19, the AUCs of the LR and SVM classifiers for speech\n",
            "    signals were significantly lower than those for breathing and\n",
            "    coughing signals. Moreover, the Decision Tree classifier showed\n",
            "    low accuracy for the group of other symptoms.\n",
            "    To address the above issues, this paper adopts a new mode, which\n",
            "    is a combination of speech and coughing, and a new classng clinically obtained statistical\n",
            "    datasets for COVID-19, it has been found that varying symptoms\n",
            "    have different prevalence, as seen in the MIT dataset [22]. In this\n",
            "    paper we introduce a unique weighting system that can utilize\n",
            "    multiple modes (non-fixed parameters) to determine the\n",
            "    influence of each individual symptom for COVID positivity.:\n",
            "*  Extensive research work is going on for classifying COVID-\n",
            "    19 patient image data. Few researchers have proposed different\n",
            "    DL models for clustering and classification of COVID-19 patient\n",
            "    image data. Some of them have used pre-trained ResNet50,\n",
            "    DenseNet121, ResNet18, etc. as the backbone for the classification\n",
            "    task [18, 19, 20].\n",
            "*  A deep transfer learning-based method has been proposed in [21]\n",
            "    for the classification of COVID-19 patient image data.\n",
            "*assifying chest x-ray images whereas some\n",
            "    others have taken CT images into consideration. Narin et. al\n",
            "    proposed three pretrained CNN models based on ResNet50,\n",
            "    InceptionV3 and Inception-ResNetV2 for detecting COVID-\n",
            "    19 patient from chest X-ray radiographs [24]. It is found that\n",
            "    ResNet 50 gives the classifying accuracy of 98% whereas InceptionV3\n",
            "    and Inception-ResNetV2 perform with the accuracy\n",
            "    of 97% and 87% respectively. But these models have taken\n",
            "    only 100 images (50 COVID-19 and 50 Normal) for training\n",
            "    the models.\n",
            "    In another work, Ozturk et. al proposed a deep learning\n",
            "    model DarkNet [25] for detecting COVID-19 patient from\n",
            "    chest X-ray radiographs. The dataset consists of 125\n",
            "    COVID-19 and 500 normal images. It is found that the\n",
            "    proposed model achieves an accuracy of 98.0 and 50 normal Chest X-rays)\n",
            "    into consideration for training which might result in declined\n",
            "    accuracy for a higher number of training images. Zhang et\n",
            "    al. propose a DL model for Coronavirus patient screening\n",
            "    using their chest X-ray images [25]. This research group has used 100 chest X-ray images of 70 COVID-19 patients and\n",
            "    1431 X-ray images of other pneumonia patients where they\n",
            "    are classified as COVID-19 and non-COVID-19 respectively.\n",
            "    This model is formed of three main parts: bacbone,\n",
            "    classifier, and localization. The backbone is used for\n",
            "    feature extraction, the classifier is used for classification,\n",
            "    and the localization is used to determine the infected\n",
            "    area in the X-ray image. In the second study, a model based\n",
            "    on CNN is proposed [26]. In this model, the authors used 120\n",
            "    chest X-ray images of 70 COVID-19 patients and kbone networks,\n",
            "    classification head, and anomaly detection head. The backbone\n",
            "    network is a 18 residual CNN layer pre-trained on ImageNet\n",
            "    dataset and it is mentionable that ImageNet provides a huge\n",
            "    number of a generalized dataset for image classifications. This\n",
            "    model can diagnosis COVID-19 and non-COVID-19 patients\n",
            "    with an accuracy of 96% and 70.65% respectively. Hall et al.\n",
            "    also worked on finding COVID-19 patients from a small set of\n",
            "    chest X-ray images with DL [26]. They have used a CNN model\n",
            "    with 13 layers to classify the COVID-19 and non-COVID-19\n",
            "    patients. They have used 75 chest X-ray images of COVID-19\n",
            "    and 500 chest X-ray images of non-COVID-19 patients for the\n",
            "    training purpose. They have also used 25 chest X-ray images\n",
            "    of COVID-19 and 50 chest X used pre-trained\n",
            "    ResNet50 and VGG 16 along with their own CNN and this\n",
            "    model generates the overall accuracy of 91.24%. Sethy and\n",
            "    Behea have also utilized deep features for Coronavirus disease\n",
            "    detection [27]. Their model is based on ResNet50 plus SVM\n",
            "    which achieved the accuracy and F1-score of 95.38% and\n",
            "    91.41% respectively. Apostolopoulos and Mpesiana utilized\n",
            "    CNN transfer learning for detecting COVID-19 with X-ray\n",
            "    images [28]. This work has considered 224 chest X-ray images\n",
            "    of normal, bacterial pneumonia and COVID-19 viral\n",
            "    pneumonia. They have used pre-trained VGG16, VGG19,\n",
            "    MobileNet v2, Inception, Xception and Inception ResNet v2\n",
            "    models. The overall accuracy of 96.78% is achieved by\n",
            "    using VGG19.\n",
            "    of COVID-19 infected people, 714 images with Pneumonia\n",
            "    and 504 images of normal people for training their model.\n",
            "    This model achieved the accuracy of 96.78% and sensitivity\n",
            "    and specificity of 98.66% and 96.46% respectively. Li et al.\n",
            "    used the patients’ chest CT images for detecting COVID-19\n",
            "    with the developed CNN architecture called COVNet [29].\n",
            "    This research group has obtained sensitivity, specificity and\n",
            "    126 Area Under the Receiver Operating Curve (AUC) of 90%,\n",
            "    96% and 0.96 respectively.\n",
            "    Transfer learning is another method for building COVID-19\n",
            "    detection models by using pre-trained CNN architectures.\n",
            "    Transfer learning is a technique that can be used in various\n",
            "    fields of artificial intelligence. The main idea is to use\n",
            "    the knowledge learned from one task and to apply it to\n",
            "    another similar task to improve the performance.\n",
            "    In this study, a transfer learning approach is used to build\n",
            "    a0.96 respectively. Other researchers have also put an\n",
            "    effort to detect COVID-19 patient from chest X-ray images in\n",
            "    [30] [31].\n",
            "    The proposed method in this paper is an improvement of the\n",
            "    method used in [29]. The method used in [29] is a single\n",
            "    shot detector (SSD) which is a real-time object detection\n",
            "    algorithm based on a deep convolutional neural network\n",
            "    (CNN) [32]. The method used in this paper is a faster\n",
            "    R-CNN (Faster R-CNN) which is a convolut\n",
            "Score d'hallicination : [0.9972537]\n",
            "cosine similarity : 0.90508854\n",
            "\n",
            "Références seules:\n",
            "[6]\n",
            "[7]\n",
            "[8]\n",
            "[9]\n",
            "[9]\n",
            "[10]\n",
            "[11]\n",
            "[12]\n",
            "[12]\n",
            "[13]\n",
            "[14]\n",
            "[13]\n",
            "[14]\n",
            "[15]\n",
            "[15]\n",
            "[16]\n",
            "[14]\n",
            "[15]\n",
            "[21]\n",
            "[25]\n",
            "[27]\n",
            "[26]\n",
            "[22]\n",
            "[27]\n",
            "[29]\n",
            "[23]\n",
            "[30]\n",
            "[31]\n",
            "[22]\n",
            "[32]\n",
            "[33]\n",
            "[22]\n",
            "[27]\n",
            "[29]\n",
            "[32]\n",
            "[33]\n",
            "[34]\n",
            "[39]\n",
            "[27]\n",
            "[40]\n",
            "[42]\n",
            "[27]\n",
            "[16]\n",
            "[40]\n",
            "[16]\n",
            "[28]\n",
            "[46]\n",
            "[23]\n",
            "[24]\n",
            "[25]\n",
            "[20]\n",
            "[43]\n",
            "[44]\n",
            "[20]\n",
            "[45]\n",
            "[20]\n",
            "[24]\n",
            "[17]\n",
            "[30]\n",
            "[31]\n",
            "[17]\n",
            "[22]\n",
            "[21]\n",
            "[24]\n",
            "[25]\n",
            "[25]\n",
            "[26]\n",
            "[26]\n",
            "[27]\n",
            "[28]\n",
            "[29]\n",
            "[30]\n",
            "[31]\n",
            "[29]\n",
            "[29]\n",
            "[32]\n",
            "\n",
            "Références complètes correspondantes:\n",
            "[43] A. Grünebaum, F. A. Chervenak, L. B. McCullough, J. W. Dudenhausen, E. Bornstein, and P. A. Mackowiak, “How fever is defined in COVID-19 publications: a disturbing lack of precision,” Journal of Perinatal Medicine, vol. 49, no. 3, pp. 255–261, Mar. 2021.\n",
            "[42] “COVID-19 Cough Classification using Machine Learning and Global Smartphone Recordings,” Computers in Biology and Medicine, vol. 135, p. 104572, Dec. 2020. [Online]. Available: https://arxiv.org/abs/2012.01926v2\n",
            "[39] W. Thorpe, M. Kurver, G. King, and C. Salome, “Acoustic analysis of cough,” in ANZIIS 2001 - Proceedings of the 7th Australian and New Zealand Intelligent Information Systems Conference, 2001, pp. 391–394.\n",
            "[34] M. Soliński, M. Łepek, and Ł. Kołtowski, “Automatic cough detection based on airflow signals for portable spirometry system,” Informatics in Medicine Unlocked, vol. 18, p. 100313, Jan. 2020.\n",
            " Appel de la fonction pour extraire les références\n",
            "['Soares et al. [6]', 'Wang et al. [8]', 'Barstugan et al. [9]', 'Rahimzadeh et al. [10]', 'Pathak et al. [11]', 'Seyedhosseini et al. [12]', 'Bansal et al. [12]', 'Khan et al. [13]', 'Zhang et al. [14]', 'Bukharia et al. [13]', 'Jaiswal et al. [14]', 'Silva et al. [15]', 'Wang et al. [16]']\n",
            "\n",
            "Références extraites:\n",
            "[6] E. Soares, P. Angelov, S. Biaso, M. H. Froes, and D. K. Abe, “SARS-CoV-2 CT-scan dataset: A large dataset of real patients CT scans for SARS-CoV-2 identification,” medRxiv, pp. 1–8, 2020.\n",
            "\n",
            "[8] B. X. Shuai Wang, Bo Kang, Jinlu Ma, Xianjun Zeng5, Mingming Xiao1, Jia Guo, Mengjiao Cai, Jingyi Yang, Yaodong Li, Xiangfei Meng, “A deep learning algorithm using CT images to screen for Corona Virus Disease (COVID-19),” pp. 1–27, 2020.\n",
            "\n",
            "[10] M. Rahimzadeh and A. Attar, “A NEW MODIFIED DEEP CONVOLUTIONAL NEURAL NETWORK FOR DETECTING COVID-19 FROM X-RAY IMAGES,” arXiv, vol. 19. arXiv, p. 100360, Apr. 16, 2020, doi: 10.1016/j.imu.2020.100360.\n",
            "\n",
            "[11] Y. Pathak, P. K. Shukla, A. Tiwari, S. Stalin, and S. Singh, “Deep Transfer Learning Based Classification Model for COVID-19 Disease,” IRBM, May 2020, doi: 10.1016/j.irbm.2020.05.003.\n",
            "\n",
            "[12] A. Bansal, G. Thakur, and D. Verma, “Detection of covid-19 using the ct scan image of lungs,” CEUR Workshop Proc., vol. 2786, pp. 219–227, 2021.\n",
            "\n",
            "[14] A. Jaiswal, N. Gianchandani, D. Singh, V. Kumar, and M. Kaur, “Classification of the COVID-19 infected patients using DenseNet201 based deep transfer learning,” Journal of Biomolecular Structure and Dynamics. 2020, doi: 10.1080/07391102.2020.1788642.\n",
            "\n",
            "[15] P. Silva et al., “COVID-19 detection in CT images with deep learning: A voting-based scheme and cross-datasets analysis,” Informatics in Medicine Unlocked, vol. 20. 2020, doi: 10.1016/j.imu.2020.100427.\n",
            "\n"
          ]
        }
      ]
    }
  ]
}